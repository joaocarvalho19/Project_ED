{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca828e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric: pandas and numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# graphics\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model, svm, preprocessing, tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report, f1_score\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8669676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/sensoringData_feature_prepared_20_19.0_2.csv',header = 0)\n",
    "\n",
    "# id is useless\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "df.drop('user',axis=1,inplace=True)\n",
    "df.drop('timestamp',axis=1,inplace=True)\n",
    "\n",
    "feature_list = list(df.columns[:-2])\n",
    "print(len(feature_list))\n",
    "#print(df.head())\n",
    "\n",
    "# print the number of missing \n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5d8ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Walking' 'Inactive' 'Active' 'Driving']\n",
      "['Walking' 'Inactive' 'Active' 'Driving']\n",
      "Features: 90\n",
      "Examples: 499276\n"
     ]
    }
   ],
   "source": [
    "print(df['activity'].unique())\n",
    "\n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'species'.\n",
    "#df['activity']= label_encoder.fit_transform(df['activity'])\n",
    " \n",
    "print(df['activity'].unique())\n",
    "\n",
    "y=df.values[:,-1]\n",
    "#Y = np.array(y).astype(int)\n",
    "#print(y)\n",
    "\n",
    "X=df.values[:,0:-2]\n",
    "print(f\"Features: {len(X[0])}\")\n",
    "print(f\"Examples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f56cad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.unique(y)\n",
    "#print(labels)\n",
    "quantity = [np.sum(y == label) for label in labels]\n",
    "#print(quantity)\n",
    "#print(sum(quantity))\n",
    "\n",
    "# Creating plot \n",
    "fig = plt.figure(figsize =(20, 10)) \n",
    "#plt.pie(quantity, labels=labels) \n",
    "  \n",
    "# show plot \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ccf85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Creating the window with 10 subplots.\\nplt.rcParams.update({'font.size': 8})\\nfig, axes = plt.subplots(nrows=4, ncols=3, figsize=(7,10))\\naxes = axes.ravel()\\n#Creating histograms with 50 bins\\nfor idx,ax in enumerate(axes):\\n    ax.figure\\n    binwidth= (max(df[feature_list[idx]]) - min(df[feature_list[idx]]))/40\\n    ax.hist([dfW[feature_list[idx]],dfI[feature_list[idx]],dfA[feature_list[idx]],dfD[feature_list[idx]]], bins=np.arange(min(df[feature_list[idx]]), max(df[feature_list[idx]]) + binwidth, binwidth) , alpha=0.8,stacked=True, density= True, label=['W','I','A','D'],color=['b','g','orange','r'])\\n    ax.legend(loc='upper right')\\n    ax.set_title(feature_list[idx])\\nplt.tight_layout()\\nplt.show()\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the data \n",
    "dfW=df[df['activity'] == \"Walking\"]\n",
    "dfA=df[df['activity'] == \"Active\"]\n",
    "dfI=df[df['activity'] == \"Inactive\"]\n",
    "dfD=df[df['activity'] == \"Driving\"]\n",
    "\"\"\"\n",
    "#Creating the window with 10 subplots.\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(7,10))\n",
    "axes = axes.ravel()\n",
    "#Creating histograms with 50 bins\n",
    "for idx,ax in enumerate(axes):\n",
    "    ax.figure\n",
    "    binwidth= (max(df[feature_list[idx]]) - min(df[feature_list[idx]]))/40\n",
    "    ax.hist([dfW[feature_list[idx]],dfI[feature_list[idx]],dfA[feature_list[idx]],dfD[feature_list[idx]]], bins=np.arange(min(df[feature_list[idx]]), max(df[feature_list[idx]]) + binwidth, binwidth) , alpha=0.8,stacked=True, density= True, label=['W','I','A','D'],color=['b','g','orange','r'])\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title(feature_list[idx])\n",
    "plt.tight_layout()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2b0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anova selection\n",
    "\n",
    "def get_best_x_features(X, y, num_features=50):\n",
    "    #df = (df - np.min(df))/(np.max(df) - np.min(df))\n",
    "    \n",
    "    k_bestfeatures = SelectKBest(score_func = f_classif, k=num_features)\n",
    "    k_bestfeatures.fit(X, y)\n",
    "    \n",
    "    # what are scores for the features\n",
    "    #for i in range(len(rankings.scores_)):\n",
    "        #print('Feature %d: %f' % (i, rankings.scores_[i]))\n",
    "    \n",
    "    # transform train input data\n",
    "    X_best = k_bestfeatures.transform(X)\n",
    "    return X_best\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accca8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 10\n",
      "Examples: 499276\n"
     ]
    }
   ],
   "source": [
    "X_best = get_best_x_features(X,y,10)\n",
    "print(f\"Features: {len(X_best[0])}\")\n",
    "print(f\"Examples: {len(X_best)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfb9de",
   "metadata": {},
   "source": [
    "## Train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70189039",
   "metadata": {},
   "source": [
    "#### Extract X and y train in order to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc0143ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples to train: 99855\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_best, y, test_size=0.8,random_state=109) # 70% training and 30% test\n",
    "print(\"Examples to train: {}\".format(len(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab431cb0",
   "metadata": {},
   "source": [
    "# Models Evaluation\n",
    "\n",
    "#### We use the confusion matrix to evaluate de model because our dataset is unbalanced, so accuracy is not recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ccea8d",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1e7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = StratifiedKFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944126da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "# Explain f1_score micro\n",
    "\n",
    "def run_kFold(model, X, y):\n",
    "    acc_results = []\n",
    "    f1_results = []\n",
    "    for train_indices, test_indices in k_fold.split(X,y):\n",
    "        #print(\"Train: \",train_indices.shape[0])\n",
    "        #print(\"test: \",test_indices.shape[0])\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        Xs=scaler.fit_transform(X_train)\n",
    "\n",
    "        X_test = scaler.transform(X[test_indices])\n",
    "        y_test = y[test_indices]\n",
    "        \n",
    "        #Train the model\n",
    "        model.fit(Xs,y[train_indices])\n",
    "        #Predict the response for test dataset\n",
    "        y_pred=model.predict(X_test)\n",
    "\n",
    "        #matrix = classification_report(y_test,y_pred,labels=[\"Walking\",\"Active\",\"Inactive\",\"Driving\"])\n",
    "        #print('Classification report : \\n',matrix)\n",
    "        \"\"\"cm = confusion_matrix(y_test,y_pred)\n",
    "        print(cm)\n",
    "        cm_df = pd.DataFrame(cm,\n",
    "                     index = [0,1,2,3],\n",
    "                     columns = [0,1,2,3])\n",
    "                \n",
    "        #Plotting the confusion matrix\n",
    "        plt.figure(figsize=(5,4, ))\n",
    "        sns.heatmap(cm_df, annot=True)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('Actal Values')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.show()\"\"\"\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred, average='micro')\n",
    "        f1_results.append(f1)\n",
    "        #acc = accuracy_score(y_test, y_pred)\n",
    "        #acc_results.append(acc)\n",
    "        \n",
    "    return np.mean(f1_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89160031",
   "metadata": {},
   "source": [
    "### Models Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8efe7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    #plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "    np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "        alpha=0.8, c=cmap(idx),marker=markers[idx], label=cl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f820c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a linear svm Classifier\n",
    "def linear_svm():\n",
    "    #l_svm = svm.SVC(C=1.0,kernel='linear', max_iter=1000, tol=1e-05, verbose=0)\n",
    "    \"\"\"l_svm=l_svm.fit(X_best,y)\n",
    "    plot_decision_regions(X_best, y, classifier=l_svm)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "    l_svm = svm.SVC(kernel=\"linear\", C=1, gamma=1) # one-vs-all\n",
    "    \n",
    "    return run_kFold(l_svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "321500f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a RBF svm Classifier\n",
    "def rbf_svm():\n",
    "    r_svm = svm.SVC(C=1.0,kernel='rbf', max_iter=100, tol=1e-05, verbose=0)\n",
    "\n",
    "    #l_svm = svm.SVC(kernel=\"linear\", C=1, gamma=1) # one-vs-all\n",
    "    \n",
    "    return run_kFold(r_svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa13c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "def lr(X_train, y_train):\n",
    "    regr = linear_model.LogisticRegression()\n",
    "    \n",
    "    return run_kFold(regr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db40fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "def knn(n_neigh, metric='euclidean'):\n",
    "    k_n_n = KNeighborsClassifier(n_neighbors=n_neigh, metric=metric)\n",
    "\n",
    "    return run_kFold(k_n_n, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa056e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "def dtree(criterion, max_depth):\n",
    "    clf = tree.DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)\n",
    "    \n",
    "    return run_kFold(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c65e0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def rf(n_estimators, max_depth):\n",
    "    #Create a Gaussian Classifier\n",
    "    r_forest = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "    return run_kFold(r_forest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ea57b",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36ce09f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786750782762398\n",
      "0.9066646553097912\n",
      "0.9280356318153623\n",
      "0.9420359549213433\n",
      "0.9440789220313328\n",
      "0.9404736904385516\n",
      "0.7885133693588351\n",
      "0.9068249133216439\n",
      "0.9269640819735112\n",
      "0.9420659973812998\n",
      "0.9409543750130741\n",
      "0.9392318826062219\n",
      "Best:  {'f1': 0.9440789220313328, 'candidates': ('gini', 20)}\n"
     ]
    }
   ],
   "source": [
    "# Define our candidate hyperparameters\n",
    "hp_candidates = {'criterion': ['gini', 'entropy'], 'max_depth': [2,4,8,15,20,25]}\n",
    "\n",
    "best_hp = {'f1':0, 'candidates': (' ',0)}\n",
    "for cri in hp_candidates['criterion']:\n",
    "    for max_ in hp_candidates['max_depth']:\n",
    "        dt_f1 = dtree(cri, max_)\n",
    "        print(dt_f1)\n",
    "        if dt_f1 > best_hp['f1']:\n",
    "            candidates = (cri, max_)\n",
    "            best_hp['f1'] = dt_f1\n",
    "            best_hp['candidates'] = candidates\n",
    "            \n",
    "print(\"Best: \",best_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc788b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca62ae0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9038305830587932 10 3\n",
      "0.9378098224211764 10 10\n",
      "0.9545641076272454 10 80\n",
      "0.9552250581942834 10 90\n",
      "0.9546141721088341 10 110\n",
      "0.9110309804737577 50 3\n",
      "0.9392118477471316 50 10\n",
      "0.9582394345490002 50 80\n",
      "0.9576886398021933 50 90\n",
      "0.958479787868452 50 110\n",
      "0.9096189535644945 100 3\n",
      "0.9391617784514962 100 10\n",
      "0.9585699096319338 100 80\n",
      "0.958439724970171 100 90\n",
      "0.9588302901882352 100 110\n",
      "0.909258431608728 200 3\n",
      "0.9388913834744289 200 10\n",
      "0.959030574190677 200 80\n",
      "0.9587802200902584 200 90\n",
      "0.9589805085055765 200 110\n",
      "Best:  {'f1': 0.959030574190677, 'candidates': (200, 80)}\n"
     ]
    }
   ],
   "source": [
    "# Define our candidate hyperparameters\n",
    "hp_candidates = {'n_estimators': [10, 50, 100, 200], 'max_depth': [3,10,80, 90, 110]}\n",
    "\n",
    "best_hp = {'f1':0, 'candidates': (0,0)}\n",
    "for est in hp_candidates['n_estimators']:\n",
    "    for max_ in hp_candidates['max_depth']:\n",
    "        rf_f1 = rf(est, max_)\n",
    "        print(rf_f1, est,max_)\n",
    "        if rf_f1 > best_hp['f1']:\n",
    "            candidates = (est, max_)\n",
    "            best_hp['f1'] = rf_f1\n",
    "            best_hp['candidates'] = candidates\n",
    "            \n",
    "print(\"Best: \",best_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd09ef",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61a04c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  {'f1': 0.9497871779732483, 'candidates': (3, 'manhattan')}\n"
     ]
    }
   ],
   "source": [
    "# Define our candidate hyperparameters\n",
    "hp_candidates = {'n_neighbors': [3,7], 'metrics': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}\n",
    "\n",
    "best_hp = {'f1':0, 'candidates': (3,' ')}\n",
    "for nei in hp_candidates['n_neighbors']:\n",
    "    for met in hp_candidates['metrics']:\n",
    "        knn_f1 = knn(nei, met)\n",
    "        if knn_f1 > best_hp['f1']:\n",
    "            candidates = (nei, met)\n",
    "            best_hp['f1'] = knn_f1\n",
    "            best_hp['candidates'] = candidates\n",
    "            \n",
    "print(\"Best: \",best_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4cfc7",
   "metadata": {},
   "source": [
    "### Linear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33bd001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  74891\n",
      "test:  24964\n",
      "0.8530283608396091\n",
      "Train:  74891\n",
      "test:  24964\n",
      "0.8520669764460823\n",
      "Train:  74891\n",
      "test:  24964\n",
      "0.8548710142605351\n",
      "Train:  74892\n",
      "test:  24963\n",
      "0.853743540439851\n",
      "Mean Accuracy: 0.8534274729965194\n"
     ]
    }
   ],
   "source": [
    "svm_y_pred = linear_svm()\n",
    "print(\"Mean Accuracy:\",svm_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f13e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
